adjointNodes() will need to work a little differently in this version.
Intead of introducing the adjoint nodes as we go that have special names, we
need to keep a separate set of adjoint nodes.  As we go through each node,
we will update the adjoints.


If we have these nodes:
  n0 = A
  n1 = B
  n2 = n0*n1

We start by having adjoints for each node that are 0.
  adj0 = 0
  adj1 = 0
  adj2 = 0


We begin by adding 1 to the adjoint for our final result.
  adj0 = 0
  adj1 = 0
  adj2 = 1

Then we process the last node.
  adj0 += adj2*n1
  adj1 += adj2*n0

  adj0 = 1*n1 = n1
  adj1 = 1*n0 = n0

At the end, we need to look up the adjoints for variables.
* We might do that by searching through the original nodes to find the node
  index for the variable we want, and then finding the corresponding adjoint
  node.
* Or, we might keep a gradient structure which has the node index for the
  adjoint of each variable, and we update it as we run across each variable.

Instead of explicitly managing the nodes, we could use the regular Graph type
and let the new nodes be built by operator overloading.  It seems like this
would be much slower.  We'd really need to be able to extract a node from
a graph to create a new graph which only has the referenced nodes.

adjoints = set(adjoints,i,node(newnodes,k) + node(newnodes,i))
adjoints = set(adjoints,j,node(newnodes,k) + node(newnodes,j))


The whole point of the merging mechanism is to allow us to use convenient
notation.  If we were to pass around a monad explicitly, then we could
avoid the merging.

  sum_k_i = add(nodes ,k,i)
    // Add a new node with expression Add<k,i>
    // Return the new nodes and the new index
  sum_k_j = add(sum_k_i.nodes,k,j)
  adjoints2 = set(adjoints ,i,sum_k_i.index)
  adjoints3 = set(adjoints2,j,sum_k_j.index)

Instead of trying to update an array of adjoints, it may be better to keep
appending new adjoints to the beginning.  When we need an adjoint, we just
find the first one that matches.  This may be a problem if we try to find
an element through base classes and function overloading, because we would
have an ambiguity.

---
We can do some computation with constexpr functions and convert them to types.
The basic idea is to create a class with template parameters that you want to
do calculations on, then make a static member of that class which is an array
computed with a constexpr function using the args, then have an alias template
which expands the array of values back into a type.

template <size_t... args>
struct Compute {
  static constexpr auto values = compute(args...);
};

struct MakeDoubleMap<Values,Sequence<x...>> {
  using type = List<MapEntry<x,B::values.values[x]>...>;
};

template <size_t... args>
using DoubleMap = MakeDoubleMap<Compute<args>,MakeSequence<args>>::type;

I don't know if this can be used to simplify the adjoint calculations.
---
It seems unnecessary that adjointNodes() needs us to specify the result
index.  It seems more natural if we are just calculating the adjoint of
every node, and then we use what we want.

If we do that, it means every node could have an effect on the ultimate
output, so we'd have to have a way to inject derivatives for every node.

That makes some sense.  We might end up with functions where we return
one calculated value, but also use that calculated value in other ways.
It seems like we're being wasteful if we have a node for the "initial"
derivative of every node.  We would be initializing a lot of things to zero
at runtime which could have been optimized away.

If we wanted to create a graph which had the original function values and
the derivative of the outputs as input and produced the derivatives of
the inputs, how would we do it?

Seems like it would have to have nodes which were Var<Deriv<i>>
And we'd have to return a graph which had a tuple of indices of the
derivatives of the inputs as its output.

f(a,b) = a*b
df(a,b,dresult) = (dresult*b,dresult*a)


f(args) = result
d(f)(args,dresult) = dargs

So if we treat a function as having a single input which could be a tuple,
then the derivative function would take a tuple of the args and the
derivative of the result and returns the derivative of the args.

So what is a function?
It would be a set of nodes and an indication of which nodes were inputs
and which nodes were outputs.

Graph<
  FunctionIndices<
    /*inputs*/TupleIndices<ScalarIndices<0>,ScalarIndices<1>>,
    /*outputs*/ScalarIndices<2>
  >,
  List<Nodes...>
>


It's interesting that this has the same basic structure as a variable.
It doesn't work the same way though, because the nodes are in a different
scope, so we wouldn't merge them with our other nodes.
---
It seems like a big issue that we can't mix regular values and graph values.
How do we make a single function which can be either?
What if we need to take the dot product of a vec3 made of variables with a vec3
made of constants?

If we have graphs so that they can contain runtime values, then it seems to
solve the problem, but it's harder to guarantee efficient evaluation.
It would be good if we could maintain constexpr status.  For example, if
we have x*2, we'd like this to be constexpr.  If we end up creating a graph
which has non-type constexpr nodes, then this is still good.  We should
be able to create constexpr functions which create the adjoint graph.

Do we end up creating graphs that have a set of constant values?  Like
a map from node indices to values.

This is still awkward, since we can't do things like fold the same constant
values into a single node.
---
We have an issue if one of our outputs is the same as one of our inputs.
We specify the derivatives of the error wrt the outputs, and we expect
to get the derivatives of the error wrt the inputs, but just because
an output is equal to an input doesn't mean the derivative of the error
wrt the output is the same as the derivative of the error wrt the input.
We don't have a good way to tell the difference between these.
We create nodes that represent the derivatives of the outputs, and we
need those nodes to be used when we call f.setDeriv().
It isn't clear how we do that though.
We could pass variables that represent the derivatives of certain nodes.

One thing to think about:  What if we ultimately used the same node more
than once?

It seems like we might want this situation:

f.addDeriv(x,2);
f.addDeriv(y,3);

And if x and y were the same node, we'd want the total effect to be 5.

So one approach would be to have nodes which represent "add to" operations.
Then, we wouldn't end up overwriting the values, we'd add to them, which
should give us the right answer.
* Seems like this works, but it has a downside that we have to have
  special nodes that change over time, which makes our graph no longer
  be a regular function -- i.e.  we wouldn't be able to differentiate it.

Another approach is to specify the derivative variables explicitly.  This way,
if we use the same node twice, it isn't a problem, since we'll have two
variables which contribute to the result.
* This seems to work well, but it makes the function template parameters be
  more complicated.

A third approach is to return a separate list of the nodes that are the
adjoints of our outputs.
* It's not clear that this works reliably.  For example, we may have two
  outputs which are the same two input nodes.  How do we map to them when
  we set the derivatives?
  f.setDeriv(x,2)
  f.setDeriv(y,3) // what if x==y?
