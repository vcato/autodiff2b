adjointNodes() will need to work a little differently in this version.
Intead of introducing the adjoint nodes as we go that have special names, we
need to keep a separate set of adjoint nodes.  As we go through each node,
we will update the adjoints.


If we have these nodes:
  n0 = A
  n1 = B
  n2 = n0*n1

We start by having adjoints for each node that are 0.
  adj0 = 0
  adj1 = 0
  adj2 = 0


We begin by adding 1 to the adjoint for our final result.
  adj0 = 0
  adj1 = 0
  adj2 = 1

Then we process the last node.
  adj0 += adj2*n1
  adj1 += adj2*n0

  adj0 = 1*n1 = n1
  adj1 = 1*n0 = n0

At the end, we need to look up the adjoints for variables.
* We might do that by searching through the original nodes to find the node
  index for the variable we want, and then finding the corresponding adjoint
  node.
* Or, we might keep a gradient structure which has the node index for the
  adjoint of each variable, and we update it as we run across each variable.

Instead of explicitly managing the nodes, we could use the regular Graph type
and let the new nodes be built by operator overloading.  It seems like this
would be much slower.  We'd really need to be able to extract a node from
a graph to create a new graph which only has the referenced nodes.

adjoints = set(adjoints,i,node(newnodes,k) + node(newnodes,i))
adjoints = set(adjoints,j,node(newnodes,k) + node(newnodes,j))


The whole point of the merging mechanism is to allow us to use convenient
notation.  If we were to pass around a monad explicitly, then we could
avoid the merging.

  sum_k_i = add(nodes ,k,i)
    // Add a new node with expression Add<k,i>
    // Return the new nodes and the new index
  sum_k_j = add(sum_k_i.nodes,k,j)
  adjoints2 = set(adjoints ,i,sum_k_i.index)
  adjoints3 = set(adjoints2,j,sum_k_j.index)

Instead of trying to update an array of adjoints, it may be better to keep
appending new adjoints to the beginning.  When we need an adjoint, we just
find the first one that matches.  This may be a problem if we try to find
an element through base classes and function overloading, because we would
have an ambiguity.

---
We can do some computation with constexpr functions and convert them to types.
The basic idea is to create a class with template parameters that you want to
do calculations on, then make a static member of that class which is an array
computed with a constexpr function using the args, then have an alias template
which expands the array of values back into a type.

template <size_t... args>
struct Compute {
  static constexpr auto values = compute(args...);
};

struct MakeDoubleMap<Values,Sequence<x...>> {
  using type = List<MapEntry<x,B::values.values[x]>...>;
};

template <size_t... args>
using DoubleMap = MakeDoubleMap<Compute<args>,MakeSequence<args>>::type;

I don't know if this can be used to simplify the adjoint calculations.
---
It seems unnecessary that adjointNodes() needs us to specify the result
index.  It seems more natural if we are just calculating the adjoint of
every node, and then we use what we want.

If we do that, it means every node could have an effect on the ultimate
output, so we'd have to have a way to inject derivatives for every node.

That makes some sense.  We might end up with functions where we return
one calculated value, but also use that calculated value in other ways.
It seems like we're being wasteful if we have a node for the "initial"
derivative of every node.  We would be initializing a lot of things to zero
at runtime which could have been optimized away.

If we wanted to create a graph which had the original function values and
the derivative of the outputs as input and produced the derivatives of
the inputs, how would we do it?

Seems like it would have to have nodes which were Var<Deriv<i>>
And we'd have to return a graph which had a tuple of indices of the
derivatives of the inputs as its output.

f(a,b) = a*b
df(a,b,dresult) = (dresult*b,dresult*a)


f(args) = result
d(f)(args,dresult) = dargs

So if we treat a function as having a single input which could be a tuple,
then the derivative function would take a tuple of the args and the
derivative of the result and returns the derivative of the args.

So what is a function?
It would be a set of nodes and an indication of which nodes were inputs
and which nodes were outputs.

Graph<
  FunctionIndices<
    /*inputs*/TupleIndices<ScalarIndices<0>,ScalarIndices<1>>,
    /*outputs*/ScalarIndices<2>
  >,
  List<Nodes...>
>


It's interesting that this has the same basic structure as a variable.
It doesn't work the same way though, because the nodes are in a different
scope, so we wouldn't merge them with our other nodes.
---
It seems like a big issue that we can't mix regular values and graph values.
How do we make a single function which can be either?
What if we need to take the dot product of a vec3 made of variables with a vec3
made of constants?

If we have graphs so that they can contain runtime values, then it seems to
solve the problem, but it's harder to guarantee efficient evaluation.
It would be good if we could maintain constexpr status.  For example, if
we have x*2, we'd like this to be constexpr.  If we end up creating a graph
which has non-type constexpr nodes, then this is still good.  We should
be able to create constexpr functions which create the adjoint graph.

Do we end up creating graphs that have a set of constant values?  Like
a map from node indices to values.

This is still awkward, since we can't do things like fold the same constant
values into a single node.
